Mounting:
    To mount, use minikube as such:
        minikube mount /Dir/To/Mount:/Loc/In/MiniKube
    Whichever shell runs this cmd must stay open while you want to use
    this mount point

Using AWS:
    -Initialize AWS with your credentials (account ID and secret key)
    -Start an eks session using the following commands:
        eksctl create cluster \
            --name prod \
            --version 1.17 \
            --region us-west-2 \
            --fargate

        Note: Use us-east-1 for AWS-educate accounts,
              Use your prefered region for all others

    -When you're done using AWS, you can shut down your cluster using the following command:
        eksctl delete cluster --region us-east-1 --name prod


Hadoop:
    Make sure you have an active HDFS instance running that can be
    connected to by a public IP (Not an RFC1918 address)
        Ex: 184.55.1.123 is fine
            192.168.4.4 is not fine

    To change the IP passed to all scripts and instances in this repo, use
    the ChangeIP script in the tools directory 

To run the simulator, simply run KubeController.py once you've
assured that you have a kubernetes instance, hadoop is accessible,
and you have no docker prior simulation docker containers running
